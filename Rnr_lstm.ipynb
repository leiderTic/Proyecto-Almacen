{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leiderTic/Proyecto-Almacen/blob/main/Rnr_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXk8Qcrbl3br"
      },
      "outputs": [],
      "source": [
        "# Instalaciones"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m pip install statsmodels"
      ],
      "metadata": {
        "id": "fLbb5sJ9mO3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraciones de acceso"
      ],
      "metadata": {
        "id": "Vmwk6hYRmRyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "prapo_kbmTlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importación de librerias"
      ],
      "metadata": {
        "id": "unoBxv6HmX4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "# Importando de keras las librerias mas importantes!\n",
        "from keras.models import Sequential # Arquitectura de red neuronal!\n",
        "from keras.layers import Dense      # Capa densa!\n",
        "from keras.layers import LSTM       # Capa recurrente\n",
        "from keras.layers import Dropout    # Evita el overfitting (Inactiva algunas neuronas)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "FcZMrMDjmn0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creacion de objeto datasetIngestado con atributos de los distintos dataframes del proceso"
      ],
      "metadata": {
        "id": "whVrDilNmq2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class datasetIngestadoRnrLstm():\n",
        "  def __init__(self, dataframe):\n",
        "        self.df = dataframe\n",
        "        self.df['Date'] = pd.to_datetime(self.df['Date'], dayfirst=True)\n",
        "        self.df.set_index('Date', inplace=True)\n",
        "        self.df.sort_index(inplace=True, ascending=True)\n",
        "        self.train = pd.DataFrame()\n",
        "        self.test = pd.DataFrame()\n",
        "        self.model = Sequential()\n",
        "        self.modelo_entrenado = 1\n",
        "        self.train_max = 0.0\n",
        "        self.train_min = 0.0\n",
        "        self.scaler = None\n",
        "        self.df_resultado = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def imprimir_dataset(self, n_filas):\n",
        "    print(self.df.head(n_filas))\n",
        "\n",
        "  def imprime_forma(self):\n",
        "    print(self.df.shape)\n",
        "\n",
        "\n",
        "\n",
        "  def visualiza_dataset(self, variable):\n",
        "    plt.figure(num=None, figsize=(15, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "    self.df[variable].plot()\n",
        "    plt.tight_layout()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "  def descompone_serie(self, variable, n_periodos):\n",
        "    res = sm.tsa.seasonal_decompose(self.df[variable],period=n_periodos)\n",
        "    fig = res.plot()\n",
        "    fig.set_figheight(8)\n",
        "    fig.set_figwidth(15)\n",
        "    plt.show()\n",
        "\n",
        "  def descripcion_dataset(self):\n",
        "    print(self.df.describe())\n",
        "\n",
        "  def divide_train_test(self, variable, cantidad):\n",
        "\n",
        "    self.train, self.test = self.df[[variable]].iloc[0:-cantidad], self.df[[variable]].iloc[-cantidad:len(self.df)]\n",
        "\n",
        "    return self.train, self.test\n",
        "\n",
        "  \"\"\"\n",
        "   Normalizar los data sets\n",
        "  \"\"\"\n",
        "  def escala_train_test(self, data_train, data_test):\n",
        "    self.scaler = StandardScaler()\n",
        "    self.scaler.fit(data_train)  # Ajustar el scaler solo con los datos de entrenamiento\n",
        "    train_set_scaled = self.scaler.transform(data_train)\n",
        "    test_set_scaled = self.scaler.transform(data_test)  # Escalar los datos de prueba con los parámetros del scaler ajustados en los datos de entrenamiento\n",
        "    # Convertir los arrays escalados de vuelta a DataFrames\n",
        "    train_set_scaled_df = pd.DataFrame(train_set_scaled, columns=data_train.columns, index=data_train.index)\n",
        "    test_set_scaled_df = pd.DataFrame(test_set_scaled, columns=data_test.columns, index=data_test.index)\n",
        "    return train_set_scaled_df, test_set_scaled_df\n",
        "\n",
        "  def valores_originales(self, y_test_esca, y_pred_esca, y_train_esca):\n",
        "    y_test = self.scaler.inverse_transform(y_test_esca.reshape(-1, 1)).flatten()\n",
        "    y_pred = self.scaler.inverse_transform(y_pred_esca.reshape(-1, 1)).flatten()\n",
        "    y_train = self.scaler.inverse_transform(y_train_esca.reshape(-1, 1)).flatten()\n",
        "    return y_test, y_pred, y_train\n",
        "  \"\"\"\n",
        "    Define arquitectura\n",
        "  \"\"\"\n",
        "  def create_dataset(self, X, y, v_time_steps):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - v_time_steps):\n",
        "        v = X.iloc[i:(i + v_time_steps)].values\n",
        "        Xs.append(v)\n",
        "        ys.append(y.iloc[i + v_time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "  def crea_datasets_train_test(self, data_escalada, time_steps):\n",
        "    X_data, y_data = self.create_dataset(data_escalada, data_escalada, time_steps)\n",
        "    return  X_data, y_data\n",
        "\n",
        "  def create_dataset_with_preds(self, X, y, pred_steps, v_time_steps):\n",
        "    Xs, ys = [], []\n",
        "\n",
        "    for i in range(len(X) - v_time_steps - pred_steps):\n",
        "        v = X.iloc[i:(i + v_time_steps)].values\n",
        "        Xs.append(v)\n",
        "        ys.append(y.iloc[i + v_time_steps + pred_steps - 1])\n",
        "\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "  def crea_datasets_train_test_preds(self, data_escalada, pred_steps, time_steps):\n",
        "    X_data, y_data = self.create_dataset_with_preds(data_escalada, data_escalada, pred_steps, time_steps)\n",
        "    X_data[:5]\n",
        "    return  X_data, y_data\n",
        "\n",
        "\n",
        "\n",
        "  def lstm_architecture(self, X_data, rate_dropout, units, num_layers):\n",
        "    # Inicializando the RNN\n",
        "    # self.model = Sequential()\n",
        "\n",
        "    # Agregar capas LSTM y Dropout para regularización.\n",
        "    for i in range(num_layers):\n",
        "        # Si es la última capa, no se debe retornar secuencias\n",
        "        return_sequences = True if i < num_layers - 1 else False\n",
        "        self.model.add(LSTM(units=units, return_sequences=return_sequences, input_shape=(X_data.shape[1], X_data.shape[2])))\n",
        "        self.model.add(Dropout(rate=rate_dropout))\n",
        "\n",
        "    # Capa de Salida!\n",
        "    self.model.add(Dense(units=1))\n",
        "\n",
        "    # Resumen del modelo!\n",
        "    self.model.summary()\n",
        "\n",
        "\n",
        "  def compila_red_reuronal(self, X_train, rate_dropout, optimizador, perdida,units, num_layers):\n",
        "    self.lstm_architecture(X_train,rate_dropout,units,num_layers)\n",
        "    self.model.compile(optimizer = optimizador, loss = perdida)\n",
        "\n",
        "  def ejecuta_red_reuronal(self, X_train, y_train, v_epochs, v_batch_size, v_shuffle):\n",
        "    self.modelo_entrenado = self.model.fit(X_train,\n",
        "                                          y_train,\n",
        "                                          epochs=v_epochs,\n",
        "                                          batch_size=v_batch_size,\n",
        "                                          shuffle=v_shuffle)\n",
        "\n",
        "  def grafica_de_perdida(self):\n",
        "    plt.plot(self.modelo_entrenado.history['loss'], label='train')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  def prediccion(self, X_test):\n",
        "\n",
        "    y_pred = self.model.predict(X_test)\n",
        "    y_pred=y_pred.reshape(-1, 1)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "\n",
        "  def grafica_predicciones(self, y_test, y_pred, y_train ):\n",
        "    plt.figure(num=None, figsize=(15, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "    #plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test.flatten(), marker='.', label=\"Valor real\")\n",
        "    plt.plot(np.arange(len(self.df['Total'])), self.df['Total'], marker='.', label=\"Valor real\")\n",
        "    plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred.flatten(), 'r', marker='.', label=\"Predicción\")\n",
        "    #plt.plot(np.arange(0, len(y_train)), y_train.flatten(), 'g', marker='.', label=\"Historial\")\n",
        "    plt.ylabel('')\n",
        "    plt.xlabel('')\n",
        "    plt.xticks(fontsize=20)\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.legend(fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  def grafica_proyeccion(self, y_test, y_pred, y_train ):\n",
        "    plt.figure(num=None, figsize=(15, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "    plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred.flatten(), 'r', marker='.', label=\"Predicción\")\n",
        "    plt.plot(np.arange(0, len(y_train)), y_train.flatten(), marker='.', label=\"Historial\")\n",
        "    plt.ylabel('')\n",
        "    plt.xlabel('')\n",
        "    # Aumentar el tamaño de la fuente en los índices de los ejes x y y\n",
        "    plt.xticks(fontsize=20)\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.legend(fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  def evaluacion_modelo(self, y_test, y_pred):\n",
        "    # Vemos algunos indicadores del ajuste!\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f'RMSE: ',rmse)\n",
        "    # Definimos y calculamos el MAPE (mean_absolute_percentage_error)\n",
        "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    print(f'MAPE: ',mape)\n",
        "    return rmse, mape\n",
        "\n",
        "  def dataframe_resultado(self,test, pred):\n",
        "    self.df_resultado['Date']=self.df.index[-len(pred):]\n",
        "    self.df_resultado['Valor_real']=test\n",
        "    self.df_resultado['RNR LSTM']=pred\n",
        "\n",
        "  def getdf_resultado(self):\n",
        "    return self.df_resultado"
      ],
      "metadata": {
        "id": "97hwq49rm0ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "   Variables:\n",
        "   variable - Columna del dataset a usar en la serie de tiempo\n",
        "   n_registros_test - número de registros contando desde el final de la serie a ser tomados como datos de test\n",
        "   time_steps - lag de tiempo a predecir\n",
        "   dropout - Porcentaje expresado en decimales para la cantidad de dropout de neuronas\n",
        "   optimizador - metodo de optimización 'adam'\n",
        "   perdida - metrica para controlar la perdida de gradiente\n",
        "   n_epocs - cantidad de iteraciones\n",
        "   batch  - tamaño del lote de cada iteracion\n",
        "   v_shuffle  - si shuffle sera verdadero o falso\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def genera_modelo(variable, n_registros_test, time_steps, dropout, optimizador, perdida, n_epocs, batch, v_shuffle,n_units,n_num_layers):\n",
        "  df_train, df_test = df.divide_train_test(variable, n_registros_test)\n",
        "  df_train_escalado, df_test_escalado = df.escala_train_test(df_train, df_test)\n",
        "  X_data_train, y_data_train = df.crea_datasets_train_test(df_train_escalado,time_steps)\n",
        "  X_data_test, y_data_test = df.crea_datasets_train_test(df_test_escalado,time_steps)\n",
        "  df.compila_red_reuronal(X_data_train, dropout, optimizador, perdida,n_units,n_num_layers)\n",
        "  df.ejecuta_red_reuronal(X_data_train, y_data_train, n_epocs, batch, v_shuffle)\n",
        "  df.grafica_de_perdida()\n",
        "  y_predicho = df.prediccion(X_data_test)\n",
        "  y_test_orig, y_pred_orig, y_train_orig = df.valores_originales(y_data_test, y_predicho, y_data_train)\n",
        "  df.dataframe_resultado(y_test_orig,y_pred_orig)\n",
        "  df.grafica_proyeccion(y_test_orig, y_pred_orig, y_train_orig)\n",
        "  df.grafica_predicciones(y_test_orig, y_pred_orig, y_train_orig)\n",
        "  print(y_predicho)\n",
        "  print(len(y_predicho))\n",
        "\n",
        "  return df.evaluacion_modelo(y_test_orig, y_pred_orig)\n"
      ],
      "metadata": {
        "id": "-ZiWPc2kRUEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "   Variables:\n",
        "   variable - Columna del dataset a usar en la serie de tiempo\n",
        "   n_registros_test - número de registros contando desde el final de la serie a ser tomados como datos de test\n",
        "   time_steps - lag de tiempo a predecir\n",
        "   dropout - Porcentaje expresado en decimales para la cantidad de dropout de neuronas\n",
        "   optimizador - metodo de optimización 'adam'\n",
        "   perdida - metrica para controlar la perdida de gradiente\n",
        "   n_epocs - cantidad de iteraciones\n",
        "   batch  - tamaño del lote de cada iteracion\n",
        "   v_shuffle  - si shuffle sera verdadero o falso\n",
        "   pred_steps - número de periodos a predecir\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def genera_modelo_con_preds(variable, n_registros_test, time_steps, dropout, optimizador, perdida, n_epocs, batch, v_shuffle,pred_steps,units,n_num_layers):\n",
        "\n",
        "  df_train, df_test = df.divide_train_test(variable, n_registros_test)\n",
        "\n",
        "  df_train_escalado, df_test_escalado = df.escala_train_test(df_train, df_test)\n",
        "  X_data_train, y_data_train = df.crea_datasets_train_test_preds(df_train_escalado,pred_steps,time_steps)\n",
        "\n",
        "  X_data_test, y_data_test = df.crea_datasets_train_test_preds(df_test_escalado,pred_steps,time_steps)\n",
        "\n",
        "  df.compila_red_reuronal(X_data_train, dropout, optimizador, perdida,units,n_num_layers)\n",
        "  df.ejecuta_red_reuronal(X_data_train, y_data_train, n_epocs, batch, v_shuffle)\n",
        "\n",
        "  df.grafica_de_perdida()\n",
        "\n",
        "  y_predicho = df.prediccion(X_data_test)\n",
        "\n",
        "  y_test_orig, y_pred_orig, y_train_orig = df.valores_originales(y_data_test, y_predicho, y_data_train)\n",
        "\n",
        "  df.grafica_predicciones(y_test_orig, y_pred_orig, y_train_orig)\n",
        "  #pdb.set_trace()\n",
        "  return df.evaluacion_modelo(y_test_orig, y_pred_orig)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "imn7ff5YaQo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}